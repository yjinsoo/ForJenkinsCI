* ubuntu 20.04 설치 기준
#으로 시작하는 것들이 명령어



0. 기본 환경설정  [모든 노드]
# swapoff -a
# apt -y update

1. 쿠버네티스 저장소 추가[모든 노드]
# curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
# cat << EOF > /etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF


2.containerd 및 kubeadm설치
쿠버네티스는 컨테이너 런타임 인터페이스를 지원하는 구현체를 통해
컨테이너를 사용합니다. containerd, cri-o 등이 컨테이너 런타임 인터페이스를 통해
컨테이너를 제어 할 수 있는 방법을 제공

2-1. [모든 노드]에서 도커 설치
#  wget -qO- get.docker.com | sh

도커를 통해 설치 된 containerd의 설정파일은 기본적으로 컨테이너 런타임 인터페이스가 비활성화 되어 있으므로
이를 containerd 기본 설정값으로 덮어씌은 뒤 containerd 재시작
# containerd config default > /etc/containerd/config.toml
# systemctl restart containerd.service

컨테이너 런타임 인터페이스(CRI)는 쿠버네티스가 컨테이너를 제어할 때 사용하는 일종의 프로토콜
간단하게 "컨테이너 삭제 or 생성" 등을 인터페이스로서의 정의한 표준화 된 규격을 CRI라 생각
containerd가 아니더라도 컨테이너 런타임을 지원하는 도구라면 무엇이든지 쿠버네티스와 연동 사용 가능


2-2 [모든 노드]에서 쿠버네티스에 필요한 패키지 다운로드
  * apt-get로 다운로드 할 경우 최신버전으로 다운로드 됨
# apt-get -y install kubelet kubeadm kubectl kubernetes-cni

3. 쿠버네티스 클러스터 초기화
# kubeadm init --apiserver-advertise-address 10.206.0.3 --pod-network-cidr=192.168.0.0/16 --cri-socket /run/containerd/containerd.sock

--apiserver-advertise-address
=> 다른 노드가 마스터에 접근할 수 있는 IP주소를 환경에 맞게 입력
     ** 반드시 본인의 마스터 노드 IP로 변경 후 명령어 입력

--pod-network-cidr
=> 쿠버네티스에서 사용 할 파드의 네트워크 대역, 각 서버의 네트워크 대역과 중복되지 않게 반드시 설정 필요입니다.

--cri-socket /run/containerd/containerd.sock
=> 쿠버네티스가 containerd의 컨테이너 런타임 인터페이스를 통해서 컨테이너를 사용하도록 설정 할 수 있다.
쿠버네티스가 도커, containerd 양쪽이 모두 사용 가능할 경우 도커를 우선적으로 선택하므로 명시하는 것임


초기화가 완료되면 다음과 같은 출력 결과 확인 가능
Your Kubernetes control-plane hst initialized successfully!
'
'
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
'
'
'
kubeadm join ~~~~

위에 세줄을 본사해서 그대로 [마스터 노드에] 붙여넣기
# mkdir -p $HOME/.kube
# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
# sudo chown $(id -u):$(id -g) $HOME/.kube/config

[워커노드]에 마스터노드연결을 위한 인증 
( 아래 명령어 또한 마스터노드에서 초기화가 완료되면 출력에서 확인가능함,
   반드시  --cri-socket /run/containerd/containerd.sock를 추가적으로 붙여줘야 함)

# kubeadm join 10.206.0.3:6443 --token zftfb3.9ryg9hb63qi9e008 --discovery-token-ca-cert-hash sha256:abd381689580a43b60ff13ec3eff976bb88706d340c714a510e10bd589b897a0 --cri-socket /run/containerd/containerd.sock


4. [마스터 노드] 컨테이너 네트워크 애드온 설치
쿠버네티스의 컨테이너 간 통신을 위해 flannel, weaveNet등 여러 오버레이 네트워크를 사용할 수 있지만,
이 설치 과정에서는 calico를 기준으로 설정

#kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml

# wget https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml

------------파드의 IP pool을 192.168.0.0/16으로 설정하지 않은 경우)-----------
# sed -i 's/192.168.0.0\/16/10.101.1.0\/24/' custom-resources.yaml 
**(10.101.1.0은 본인이 파드 IP범위 풀로 설정한 값으로 변경, 만약 파드 범위를
    192.168.0.0/16으로 했다면 변경 할 필요 없음)
---------------------------------------------------------------------------------------

# kubectl create -f custom-resources.yaml


5. 확인
워커 노드들 상태 확인
# kubectl get nodes   

파드들 서비스 상태 확인
#kubectl get pods -A    

아래와 같이 나와야 정상
-------------------------------------------------------------------------------------------------------------
NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-5c5c5789f-592w4           1/1     Running   0          2d2h
calico-apiserver   calico-apiserver-5c5c5789f-5xfwt           1/1     Running   0          2d2h
calico-system      calico-kube-controllers-6bd5c4c685-xcpp6   1/1     Running   0          2d2h
calico-system      calico-node-65fcn                          1/1     Running   0          2d2h
calico-system      calico-node-xgzlp                          1/1     Running   0          2d2h
calico-system      calico-typha-d66699546-htnj5               1/1     Running   0          2d2h
calico-system      csi-node-driver-bkjns                      2/2     Running   0          2d2h
calico-system      csi-node-driver-phgbq                      2/2     Running   0          2d2h
kube-system        coredns-5dd5756b68-clwfk                   1/1     Running   0          3d12h
kube-system        coredns-5dd5756b68-n8f2q                   1/1     Running   0          3d12h
kube-system        etcd-kube-master                           1/1     Running   0          3d12h
kube-system        kube-apiserver-kube-master                 1/1     Running   0          3d12h
kube-system        kube-controller-manager-kube-master        1/1     Running   0          3d12h
kube-system        kube-proxy-q7qq6                           1/1     Running   0          3d12h
kube-system        kube-proxy-xfbh6                           1/1     Running   0          3d12h
kube-system        kube-scheduler-kube-master                 1/1     Running   0          3d12h
tigera-operator    tigera-operator-94d7f7696-m86mk            1/1     Running   0          2d2h
-------------------------------------------------------------------------------------------------------------




